{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9af1cc5e",
   "metadata": {},
   "source": [
    "# Optimizer LCD sur le jeu de données FashionMnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77c42e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelques packages à charger\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np                                                                    \n",
    "from data import FASHION_MNIST_flatten    \n",
    "from keras import losses, metrics                                                     \n",
    "import tirages    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653dafcd",
   "metadata": {},
   "source": [
    "## Chargement du jeu de données Fashion Mnist (pour visualiser uniquement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f8d96f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# chargement du jeu de données\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16e047b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the class names for the dataset\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Display 20 images along with their labels\n",
    "plt.figure(figsize=(6, 4))\n",
    "for i in range(20):\n",
    "    plt.subplot(4, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62676fa",
   "metadata": {},
   "source": [
    "## Chargement du jeu de données et mise en données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17ef917c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729259971.165724   49921 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-18 15:59:31.166150: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "type='float32'                                                 \n",
    "tf.keras.backend.set_floatx(type)                                                                                      \n",
    "# Preparation du jeu de données (normalisation etc.)                  \n",
    "x_train, y_train, x_test, y_test = FASHION_MNIST_flatten(type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ff0ad1",
   "metadata": {},
   "source": [
    "## Choix de l'architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4064209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'FC' pour 'Fully Connected'\n",
    "name_model=\"FC\" \n",
    "# 784 neurones dans la première couche, 400 dans la suivante et 10 (taille de la sortie 'class_names')\n",
    "nbNeurons=[784,400,10]  \n",
    "# fonctions d'activations 'tanh' sur les couches latentes, 'softmax' sur la dernière (celle de la sortie)\n",
    "activations=['tanh','softmax']                          \n",
    "# fonction de coût 'norme L2'\n",
    "loss = losses.MeanSquaredError()\n",
    "# métrique de référence: précision en termes de classification\n",
    "metrics = [\"categorical_accuracy\"]\n",
    "# Type d'initialisation aléatoire des poids\n",
    "name_init=\"Xavier\"        \n",
    "# paramètres 'dummy' pour cette étude\n",
    "params_init=[-1,1]      \n",
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506af901",
   "metadata": {},
   "source": [
    "## Apprentissage avec l'optimiseur Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c37de72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paramètres d'arrêt (communs à tous les optimiseurs)               \n",
    "eps=10**(-4); max_epochs=1000      \n",
    "#paramètres d'entrainement communs à tous les optimiseurs                                                        \n",
    "lr=0.1\n",
    "\n",
    "# paramètres de LCEGD\n",
    "seuil=0.01                                                                            \n",
    "f1=30; f2=10000; lambd=0.5; rho=0.9; eps_egd=0.01  \n",
    "\n",
    "# paramètres d'adam (si adam est utilisé)\n",
    "beta_1=0.9; beta_2=0.999; epsilon=1e-07                                               \n",
    "amsgrad=False     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "942b4c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/npers/gpoette/ML/lib64/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 2: 0.17777067\n",
      "grad:  tf.Tensor(0.02459053, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 4: 0.17737323\n",
      "grad:  tf.Tensor(0.0505416, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 6: 0.16268885\n",
      "grad:  tf.Tensor(0.019381123, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 8: 0.16062826\n",
      "grad:  tf.Tensor(0.0008947026, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 10: 0.16060004\n",
      "grad:  tf.Tensor(0.00097149826, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 12: 0.16080460\n",
      "grad:  tf.Tensor(0.0017533407, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 14: 0.16029365\n",
      "grad:  tf.Tensor(0.0010745389, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 16: 0.15932447\n",
      "grad:  tf.Tensor(0.020184739, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 18: 0.16081934\n",
      "grad:  tf.Tensor(0.0003136107, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 20: 0.16085395\n",
      "grad:  tf.Tensor(0.00025263746, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 22: 0.16086642\n",
      "grad:  tf.Tensor(0.00039818947, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 24: 0.16089024\n",
      "grad:  tf.Tensor(0.0004658217, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 26: 0.16092390\n",
      "grad:  tf.Tensor(0.00064735394, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 28: 0.16083604\n",
      "grad:  tf.Tensor(0.00043940498, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 30: 0.16071491\n",
      "grad:  tf.Tensor(0.00048328048, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 32: 0.16055770\n",
      "grad:  tf.Tensor(0.0010709179, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 34: 0.16030696\n",
      "grad:  tf.Tensor(0.00048350953, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 36: 0.15960205\n",
      "grad:  tf.Tensor(0.0015672795, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 38: 0.15865058\n",
      "grad:  tf.Tensor(0.009612376, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 40: 0.15850069\n",
      "grad:  tf.Tensor(0.012432662, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 42: 0.16100904\n",
      "grad:  tf.Tensor(0.00031609458, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 44: 0.16113067\n",
      "grad:  tf.Tensor(0.0003476822, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 46: 0.16122659\n",
      "grad:  tf.Tensor(0.00040245635, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 48: 0.16123649\n",
      "grad:  tf.Tensor(0.00050885335, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 50: 0.16111992\n",
      "grad:  tf.Tensor(0.0008348584, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 52: 0.16010673\n",
      "grad:  tf.Tensor(0.010531229, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 54: 0.16088669\n",
      "grad:  tf.Tensor(0.00032273142, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 56: 0.16089219\n",
      "grad:  tf.Tensor(0.00016518742, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 58: 0.16077928\n",
      "grad:  tf.Tensor(0.0005288409, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 60: 0.16059892\n",
      "grad:  tf.Tensor(0.00089459564, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 62: 0.15954560\n",
      "grad:  tf.Tensor(0.02223082, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 64: 0.16147509\n",
      "grad:  tf.Tensor(0.0012506242, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 66: 0.16211823\n",
      "grad:  tf.Tensor(0.0010632533, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 68: 0.16283655\n",
      "grad:  tf.Tensor(0.0012254522, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 70: 0.16299368\n",
      "grad:  tf.Tensor(0.00195207, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 72: 0.16219245\n",
      "grad:  tf.Tensor(0.0012733807, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 74: 0.16145933\n",
      "grad:  tf.Tensor(0.00095979654, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 76: 0.16011539\n",
      "grad:  tf.Tensor(0.0056705982, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 78: 0.16128574\n",
      "grad:  tf.Tensor(0.0054879584, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 80: 0.16139960\n",
      "grad:  tf.Tensor(0.0030867727, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 82: 0.16040537\n",
      "grad:  tf.Tensor(0.008030116, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 84: 0.15955767\n",
      "grad:  tf.Tensor(0.0031760046, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 86: 0.15906742\n",
      "grad:  tf.Tensor(0.0049437475, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 88: 0.15711571\n",
      "grad:  tf.Tensor(0.0029127775, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 90: 0.16308011\n",
      "grad:  tf.Tensor(0.006502457, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 92: 0.16518585\n",
      "grad:  tf.Tensor(0.001048891, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 94: 0.16529645\n",
      "grad:  tf.Tensor(0.0011471253, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 96: 0.16515465\n",
      "grad:  tf.Tensor(0.0025953937, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 98: 0.16419272\n",
      "grad:  tf.Tensor(0.0021459966, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 100: 0.16300088\n",
      "grad:  tf.Tensor(0.0006250341, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 102: 0.16187100\n",
      "grad:  tf.Tensor(0.00075626816, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 104: 0.16085969\n",
      "grad:  tf.Tensor(0.002238594, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 106: 0.16015109\n",
      "grad:  tf.Tensor(0.01581169, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 108: 0.16134578\n",
      "grad:  tf.Tensor(0.0017450132, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 110: 0.16068240\n",
      "grad:  tf.Tensor(0.00088303105, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 112: 0.16044024\n",
      "grad:  tf.Tensor(0.00442497, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 114: 0.16041586\n",
      "grad:  tf.Tensor(0.0015372109, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 116: 0.15908551\n",
      "grad:  tf.Tensor(0.0037314729, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 118: 0.16055410\n",
      "grad:  tf.Tensor(0.0016299388, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 120: 0.16498847\n",
      "grad:  tf.Tensor(0.002959479, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 122: 0.16519384\n",
      "grad:  tf.Tensor(0.0026164267, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 124: 0.16341995\n",
      "grad:  tf.Tensor(0.0022746983, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 126: 0.16087180\n",
      "grad:  tf.Tensor(0.004830778, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 128: 0.16007175\n",
      "grad:  tf.Tensor(0.001091523, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 130: 0.16005003\n",
      "grad:  tf.Tensor(0.0032843146, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 132: 0.15866266\n",
      "grad:  tf.Tensor(0.03488331, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 134: 0.15960045\n",
      "grad:  tf.Tensor(0.0020277877, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 136: 0.15612350\n",
      "grad:  tf.Tensor(0.033506658, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 138: 0.16414385\n",
      "grad:  tf.Tensor(0.0033339893, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 140: 0.16635393\n",
      "grad:  tf.Tensor(0.0037320165, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 142: 0.16458845\n",
      "grad:  tf.Tensor(0.0018105702, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 144: 0.16273265\n",
      "grad:  tf.Tensor(0.001302255, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 146: 0.16099550\n",
      "grad:  tf.Tensor(0.0011677139, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 148: 0.15972760\n",
      "grad:  tf.Tensor(0.0030964161, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 150: 0.15973200\n",
      "grad:  tf.Tensor(0.010084543, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 152: 0.16046572\n",
      "grad:  tf.Tensor(0.00057647075, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 154: 0.16104345\n",
      "grad:  tf.Tensor(0.00031573517, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 156: 0.16113693\n",
      "grad:  tf.Tensor(0.00047235383, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 158: 0.16124977\n",
      "grad:  tf.Tensor(0.00023987172, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 160: 0.16131894\n",
      "grad:  tf.Tensor(0.0004416102, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 162: 0.16136368\n",
      "grad:  tf.Tensor(0.00039752564, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 164: 0.16136463\n",
      "grad:  tf.Tensor(0.0005296388, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 166: 0.16130029\n",
      "grad:  tf.Tensor(0.0009229784, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 168: 0.16111423\n",
      "grad:  tf.Tensor(0.0002354682, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 170: 0.16100676\n",
      "grad:  tf.Tensor(0.00036039192, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 172: 0.16088645\n",
      "grad:  tf.Tensor(0.0002804493, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 174: 0.16069633\n",
      "grad:  tf.Tensor(0.0017728888, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 176: 0.16049857\n",
      "grad:  tf.Tensor(0.0099243885, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 178: 0.16072434\n",
      "grad:  tf.Tensor(0.0002715341, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 180: 0.16062634\n",
      "grad:  tf.Tensor(0.00027418105, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 182: 0.16059670\n",
      "grad:  tf.Tensor(0.00042401763, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 184: 0.16054298\n",
      "grad:  tf.Tensor(0.0008717985, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 186: 0.16024634\n",
      "grad:  tf.Tensor(0.0012579565, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 188: 0.15939039\n",
      "grad:  tf.Tensor(0.017525721, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 190: 0.16061445\n",
      "grad:  tf.Tensor(0.00018819855, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 192: 0.16057616\n",
      "grad:  tf.Tensor(0.00035342743, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 194: 0.16043128\n",
      "grad:  tf.Tensor(0.0014535079, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 196: 0.15985233\n",
      "grad:  tf.Tensor(0.0038703978, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 198: 0.16343297\n",
      "grad:  tf.Tensor(0.0042182608, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 200: 0.16837397\n",
      "grad:  tf.Tensor(0.0077432017, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 202: 0.16573298\n",
      "grad:  tf.Tensor(0.005471606, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 204: 0.16086005\n",
      "grad:  tf.Tensor(0.0012140652, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 206: 0.15994108\n",
      "grad:  tf.Tensor(0.00069770217, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 208: 0.16038223\n",
      "grad:  tf.Tensor(0.00044937053, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 210: 0.16038951\n",
      "grad:  tf.Tensor(0.00047263608, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 212: 0.16069463\n",
      "grad:  tf.Tensor(0.00053723744, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 214: 0.16104919\n",
      "grad:  tf.Tensor(0.00077312166, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 216: 0.16137849\n",
      "grad:  tf.Tensor(0.00075045385, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 218: 0.16141842\n",
      "grad:  tf.Tensor(0.0007487423, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 220: 0.16118217\n",
      "grad:  tf.Tensor(0.0011298332, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 222: 0.16083734\n",
      "grad:  tf.Tensor(0.00042258398, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 224: 0.16075951\n",
      "grad:  tf.Tensor(0.00052890764, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 226: 0.16051199\n",
      "grad:  tf.Tensor(0.0015897283, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 228: 0.16036011\n",
      "grad:  tf.Tensor(0.004139624, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 230: 0.16018884\n",
      "grad:  tf.Tensor(0.0044585257, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 232: 0.15987909\n",
      "grad:  tf.Tensor(0.013831142, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 234: 0.16242044\n",
      "grad:  tf.Tensor(0.00052684214, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 236: 0.16302291\n",
      "grad:  tf.Tensor(0.0008193579, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 238: 0.16319534\n",
      "grad:  tf.Tensor(0.0011330864, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 240: 0.16306035\n",
      "grad:  tf.Tensor(0.0013550528, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 242: 0.16255704\n",
      "grad:  tf.Tensor(0.0019366038, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 244: 0.16210723\n",
      "grad:  tf.Tensor(0.00059924123, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 246: 0.16182767\n",
      "grad:  tf.Tensor(0.000198858, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 248: 0.16159202\n",
      "grad:  tf.Tensor(0.0002663712, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 250: 0.16144302\n",
      "grad:  tf.Tensor(0.0003190513, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 252: 0.16122915\n",
      "grad:  tf.Tensor(0.00028773473, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 254: 0.16103415\n",
      "grad:  tf.Tensor(0.00032798023, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 256: 0.16083382\n",
      "grad:  tf.Tensor(0.0019251965, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 258: 0.16068874\n",
      "grad:  tf.Tensor(0.0032579964, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 260: 0.16066973\n",
      "grad:  tf.Tensor(0.0013745765, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 262: 0.16066203\n",
      "grad:  tf.Tensor(0.00043712236, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 264: 0.16049762\n",
      "grad:  tf.Tensor(0.0019155173, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 266: 0.15976806\n",
      "grad:  tf.Tensor(0.00385996, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 268: 0.15755866\n",
      "grad:  tf.Tensor(0.042295612, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 270: 0.16077426\n",
      "grad:  tf.Tensor(0.0001905946, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 272: 0.16085616\n",
      "grad:  tf.Tensor(0.00021591866, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 274: 0.16088675\n",
      "grad:  tf.Tensor(0.00060211436, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 276: 0.16113392\n",
      "grad:  tf.Tensor(0.0008110577, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 278: 0.16149248\n",
      "grad:  tf.Tensor(0.0011710911, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 280: 0.16224915\n",
      "grad:  tf.Tensor(0.003673895, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 282: 0.16151813\n",
      "grad:  tf.Tensor(0.0034627744, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 284: 0.16080739\n",
      "grad:  tf.Tensor(0.0025214632, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 286: 0.16064613\n",
      "grad:  tf.Tensor(0.0019475337, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 288: 0.16083923\n",
      "grad:  tf.Tensor(0.00044521113, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 290: 0.16076897\n",
      "grad:  tf.Tensor(0.0004329099, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 292: 0.16073211\n",
      "grad:  tf.Tensor(0.00044484474, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 294: 0.16068269\n",
      "grad:  tf.Tensor(0.00040553056, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 296: 0.16064419\n",
      "grad:  tf.Tensor(0.00037465303, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 298: 0.16027944\n",
      "grad:  tf.Tensor(0.00046266953, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 300: 0.16015118\n",
      "grad:  tf.Tensor(0.003930686, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 302: 0.16038024\n",
      "grad:  tf.Tensor(0.0018081965, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 304: 0.16065827\n",
      "grad:  tf.Tensor(0.0016075192, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 306: 0.16003388\n",
      "grad:  tf.Tensor(0.0030669605, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 308: 0.15895995\n",
      "grad:  tf.Tensor(0.010304606, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 310: 0.16069175\n",
      "grad:  tf.Tensor(0.0001711486, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 312: 0.16071253\n",
      "grad:  tf.Tensor(0.00024382176, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 314: 0.16073303\n",
      "grad:  tf.Tensor(0.00032368104, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 316: 0.16070911\n",
      "grad:  tf.Tensor(0.0002100755, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 318: 0.16079071\n",
      "grad:  tf.Tensor(0.00019177343, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 320: 0.16080135\n",
      "grad:  tf.Tensor(0.00029516543, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 322: 0.16083421\n",
      "grad:  tf.Tensor(0.00032527308, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 324: 0.16090433\n",
      "grad:  tf.Tensor(0.00065977144, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 326: 0.16089793\n",
      "grad:  tf.Tensor(0.00039062335, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 328: 0.16086528\n",
      "grad:  tf.Tensor(0.0001876188, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 330: 0.16076703\n",
      "grad:  tf.Tensor(0.0013048057, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 332: 0.16041876\n",
      "grad:  tf.Tensor(0.0040033828, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 334: 0.15980007\n",
      "grad:  tf.Tensor(0.015939623, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 336: 0.16131811\n",
      "grad:  tf.Tensor(0.00093308673, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 338: 0.16196525\n",
      "grad:  tf.Tensor(0.0008491088, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 340: 0.16204996\n",
      "grad:  tf.Tensor(0.0023359975, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 342: 0.16167524\n",
      "grad:  tf.Tensor(0.00039599903, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 344: 0.16125061\n",
      "grad:  tf.Tensor(0.0011690286, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 346: 0.16094226\n",
      "grad:  tf.Tensor(0.00056501984, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 348: 0.16067396\n",
      "grad:  tf.Tensor(0.0003593691, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 350: 0.16057099\n",
      "grad:  tf.Tensor(0.00028017635, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 352: 0.16057871\n",
      "grad:  tf.Tensor(0.000459611, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 354: 0.16057134\n",
      "grad:  tf.Tensor(0.0013208135, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 356: 0.16053219\n",
      "grad:  tf.Tensor(0.0019755682, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 358: 0.16050084\n",
      "grad:  tf.Tensor(0.0010588213, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 360: 0.16018146\n",
      "grad:  tf.Tensor(0.0032246069, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 362: 0.15862373\n",
      "grad:  tf.Tensor(0.016695546, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 364: 0.16061725\n",
      "grad:  tf.Tensor(0.00024057551, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 366: 0.16064914\n",
      "grad:  tf.Tensor(0.00027081082, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 368: 0.16062978\n",
      "grad:  tf.Tensor(0.0004313774, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 370: 0.16061620\n",
      "grad:  tf.Tensor(0.00075993006, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 372: 0.16053417\n",
      "grad:  tf.Tensor(0.0013444389, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 374: 0.16057956\n",
      "grad:  tf.Tensor(0.0004893635, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 376: 0.15973099\n",
      "grad:  tf.Tensor(0.010523297, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 378: 0.16121314\n",
      "grad:  tf.Tensor(0.0015005326, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 380: 0.16173719\n",
      "grad:  tf.Tensor(0.0008328294, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 382: 0.16187851\n",
      "grad:  tf.Tensor(0.000668244, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 384: 0.16196109\n",
      "grad:  tf.Tensor(0.003443476, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 386: 0.16015878\n",
      "grad:  tf.Tensor(0.0011483997, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 388: 0.16054580\n",
      "grad:  tf.Tensor(0.00036824273, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 390: 0.16056120\n",
      "grad:  tf.Tensor(0.00029312194, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 392: 0.16050944\n",
      "grad:  tf.Tensor(0.00025500366, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 394: 0.16030121\n",
      "grad:  tf.Tensor(0.0035920672, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 396: 0.16059391\n",
      "grad:  tf.Tensor(0.00032419572, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 398: 0.16061330\n",
      "grad:  tf.Tensor(0.000582852, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 400: 0.16072989\n",
      "grad:  tf.Tensor(0.00037070742, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 402: 0.16074201\n",
      "grad:  tf.Tensor(0.00033329942, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 404: 0.16068558\n",
      "grad:  tf.Tensor(0.0003226421, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 406: 0.16062611\n",
      "grad:  tf.Tensor(0.0005779035, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 408: 0.16048701\n",
      "grad:  tf.Tensor(0.0007823039, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 410: 0.15998490\n",
      "grad:  tf.Tensor(0.0051749237, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 412: 0.16053824\n",
      "grad:  tf.Tensor(0.0003611819, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 414: 0.16050798\n",
      "grad:  tf.Tensor(0.00021633133, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 416: 0.16047584\n",
      "grad:  tf.Tensor(0.0003418177, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 418: 0.16034281\n",
      "grad:  tf.Tensor(0.0019551825, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 420: 0.16042332\n",
      "grad:  tf.Tensor(0.0018362651, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 422: 0.16016300\n",
      "grad:  tf.Tensor(0.0008939762, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 424: 0.16009098\n",
      "grad:  tf.Tensor(0.0016206987, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 426: 0.16033961\n",
      "grad:  tf.Tensor(0.0027960704, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 428: 0.15992251\n",
      "grad:  tf.Tensor(0.0023469664, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 430: 0.16072331\n",
      "grad:  tf.Tensor(0.0008705665, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 432: 0.16087286\n",
      "grad:  tf.Tensor(0.00020908506, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 434: 0.16106807\n",
      "grad:  tf.Tensor(0.0007518895, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 436: 0.16107103\n",
      "grad:  tf.Tensor(0.0002903233, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 438: 0.16097735\n",
      "grad:  tf.Tensor(0.00027683435, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 440: 0.16064258\n",
      "grad:  tf.Tensor(0.0013323027, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 442: 0.16043939\n",
      "grad:  tf.Tensor(0.0046304488, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 444: 0.16011813\n",
      "grad:  tf.Tensor(0.006635214, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 446: 0.16069089\n",
      "grad:  tf.Tensor(0.0006860808, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 448: 0.16064563\n",
      "grad:  tf.Tensor(0.0018541282, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 450: 0.16045749\n",
      "grad:  tf.Tensor(0.0037500195, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 452: 0.16062224\n",
      "grad:  tf.Tensor(0.0023668353, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 454: 0.16087960\n",
      "grad:  tf.Tensor(0.00025942968, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 456: 0.16090928\n",
      "grad:  tf.Tensor(0.0016261223, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 458: 0.16034825\n",
      "grad:  tf.Tensor(0.0021840243, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 460: 0.16042803\n",
      "grad:  tf.Tensor(0.0073816115, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 462: 0.16024235\n",
      "grad:  tf.Tensor(0.00094039086, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 464: 0.16131741\n",
      "grad:  tf.Tensor(0.000557199, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 466: 0.16367875\n",
      "grad:  tf.Tensor(0.00069483556, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 468: 0.17265230\n",
      "grad:  tf.Tensor(0.0027168423, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 470: 0.17070980\n",
      "grad:  tf.Tensor(0.004087372, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 472: 0.16723578\n",
      "grad:  tf.Tensor(0.0014557365, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 474: 0.16459137\n",
      "grad:  tf.Tensor(0.0006407715, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 476: 0.16249889\n",
      "grad:  tf.Tensor(0.00076479936, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 478: 0.16151188\n",
      "grad:  tf.Tensor(0.0007184223, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 480: 0.16097583\n",
      "grad:  tf.Tensor(0.00059639645, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 482: 0.16093077\n",
      "grad:  tf.Tensor(0.00066034053, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 484: 0.16064264\n",
      "grad:  tf.Tensor(0.0019466622, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 486: 0.15931979\n",
      "grad:  tf.Tensor(0.013909102, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 488: 0.16041605\n",
      "grad:  tf.Tensor(0.0025328798, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 490: 0.16057719\n",
      "grad:  tf.Tensor(0.0009848747, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 492: 0.16043538\n",
      "grad:  tf.Tensor(0.0009889305, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 494: 0.16062197\n",
      "grad:  tf.Tensor(0.00017961947, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 496: 0.16055693\n",
      "grad:  tf.Tensor(0.0003063589, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 498: 0.16057204\n",
      "grad:  tf.Tensor(0.0002682352, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 500: 0.16052334\n",
      "grad:  tf.Tensor(0.00031218844, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 502: 0.16049135\n",
      "grad:  tf.Tensor(0.00021702061, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 504: 0.16048773\n",
      "grad:  tf.Tensor(0.00036924228, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 506: 0.16048060\n",
      "grad:  tf.Tensor(0.0004407922, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 508: 0.16024899\n",
      "grad:  tf.Tensor(0.0018179571, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 510: 0.16014391\n",
      "grad:  tf.Tensor(0.0054786443, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 512: 0.16051394\n",
      "grad:  tf.Tensor(0.000166772, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 514: 0.16024874\n",
      "grad:  tf.Tensor(0.0029877066, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 516: 0.16031539\n",
      "grad:  tf.Tensor(0.0013267215, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 518: 0.16050492\n",
      "grad:  tf.Tensor(0.0005929184, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 520: 0.16021244\n",
      "grad:  tf.Tensor(0.004430093, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 522: 0.16039039\n",
      "grad:  tf.Tensor(0.00024946273, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 524: 0.16026743\n",
      "grad:  tf.Tensor(0.0028519072, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 526: 0.16047320\n",
      "grad:  tf.Tensor(0.00031752855, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 528: 0.16052331\n",
      "grad:  tf.Tensor(0.0005244818, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 530: 0.16041945\n",
      "grad:  tf.Tensor(0.003597817, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 532: 0.16034453\n",
      "grad:  tf.Tensor(0.0023709065, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 534: 0.16004057\n",
      "grad:  tf.Tensor(0.011719437, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 536: 0.16081610\n",
      "grad:  tf.Tensor(0.00019149024, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 538: 0.16095743\n",
      "grad:  tf.Tensor(0.0002828954, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 540: 0.16100127\n",
      "grad:  tf.Tensor(0.00024197246, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 542: 0.16104853\n",
      "grad:  tf.Tensor(0.00039753428, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 544: 0.16112852\n",
      "grad:  tf.Tensor(0.00025714198, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 546: 0.16121569\n",
      "grad:  tf.Tensor(0.00022896723, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 548: 0.16123255\n",
      "grad:  tf.Tensor(0.00021983834, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 550: 0.16118923\n",
      "grad:  tf.Tensor(0.00030555436, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 552: 0.16110422\n",
      "grad:  tf.Tensor(0.0002986837, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 554: 0.16101567\n",
      "grad:  tf.Tensor(0.00036227706, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 556: 0.16072080\n",
      "grad:  tf.Tensor(0.0022705242, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 558: 0.16077213\n",
      "grad:  tf.Tensor(0.0047664675, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 560: 0.15972745\n",
      "grad:  tf.Tensor(0.0062254923, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 562: 0.16092727\n",
      "grad:  tf.Tensor(0.0011180039, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 564: 0.16106853\n",
      "grad:  tf.Tensor(0.002036693, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 566: 0.16013531\n",
      "grad:  tf.Tensor(0.009725704, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 568: 0.16122952\n",
      "grad:  tf.Tensor(0.0012975056, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 570: 0.16098925\n",
      "grad:  tf.Tensor(0.0008952807, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 572: 0.16038384\n",
      "grad:  tf.Tensor(0.006034747, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 574: 0.16063812\n",
      "grad:  tf.Tensor(0.00057017885, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 576: 0.16057506\n",
      "grad:  tf.Tensor(0.0012485972, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 578: 0.16045865\n",
      "grad:  tf.Tensor(0.0029640198, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 580: 0.16057982\n",
      "grad:  tf.Tensor(0.0002875987, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 582: 0.16055517\n",
      "grad:  tf.Tensor(0.00024008422, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 584: 0.16052967\n",
      "grad:  tf.Tensor(0.000521866, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 586: 0.16051462\n",
      "grad:  tf.Tensor(0.00030237564, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 588: 0.16015446\n",
      "grad:  tf.Tensor(0.001092627, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 590: 0.16055804\n",
      "grad:  tf.Tensor(0.001046323, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 592: 0.16099754\n",
      "grad:  tf.Tensor(0.00052407663, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 594: 0.15987678\n",
      "grad:  tf.Tensor(0.01959693, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 596: 0.16055898\n",
      "grad:  tf.Tensor(0.00051895, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 598: 0.16064699\n",
      "grad:  tf.Tensor(0.00034908802, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 600: 0.16066635\n",
      "grad:  tf.Tensor(0.00027786082, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 602: 0.16060801\n",
      "grad:  tf.Tensor(0.0003145422, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 604: 0.16045819\n",
      "grad:  tf.Tensor(0.0006748507, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 606: 0.15987520\n",
      "grad:  tf.Tensor(0.001925497, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 608: 0.16049482\n",
      "grad:  tf.Tensor(0.0003128591, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 610: 0.16001943\n",
      "grad:  tf.Tensor(0.0013461063, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 612: 0.16225511\n",
      "grad:  tf.Tensor(0.005502587, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 614: 0.16440775\n",
      "grad:  tf.Tensor(0.0010885979, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 616: 0.16415763\n",
      "grad:  tf.Tensor(0.0014100057, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 618: 0.16428746\n",
      "grad:  tf.Tensor(0.0058945725, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 620: 0.16166130\n",
      "grad:  tf.Tensor(0.0010207025, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 622: 0.16062950\n",
      "grad:  tf.Tensor(0.0006234588, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 624: 0.16031680\n",
      "grad:  tf.Tensor(0.0020468214, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 626: 0.15919468\n",
      "grad:  tf.Tensor(0.0050684363, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 628: 0.16030586\n",
      "grad:  tf.Tensor(0.0004594636, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 630: 0.16020223\n",
      "grad:  tf.Tensor(0.0014114423, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 632: 0.16031608\n",
      "grad:  tf.Tensor(0.002475793, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 634: 0.16024889\n",
      "grad:  tf.Tensor(0.0005484087, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 636: 0.16016582\n",
      "grad:  tf.Tensor(0.0010719759, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 638: 0.16185787\n",
      "grad:  tf.Tensor(0.0013554415, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 640: 0.16991714\n",
      "grad:  tf.Tensor(0.009542358, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 642: 0.16205060\n",
      "grad:  tf.Tensor(0.009790462, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 644: 0.16031981\n",
      "grad:  tf.Tensor(0.0005183389, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 646: 0.16058099\n",
      "grad:  tf.Tensor(0.0003801279, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 648: 0.16061611\n",
      "grad:  tf.Tensor(0.0006037008, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 650: 0.16069293\n",
      "grad:  tf.Tensor(0.00030054903, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 652: 0.16093206\n",
      "grad:  tf.Tensor(0.001106543, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 654: 0.16108806\n",
      "grad:  tf.Tensor(0.0008552799, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 656: 0.16133730\n",
      "grad:  tf.Tensor(0.00083303027, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 658: 0.16118857\n",
      "grad:  tf.Tensor(0.00032129782, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 660: 0.16116531\n",
      "grad:  tf.Tensor(0.00034063586, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 662: 0.16123129\n",
      "grad:  tf.Tensor(0.00071210304, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 664: 0.16139373\n",
      "grad:  tf.Tensor(0.0011738926, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 666: 0.16112290\n",
      "grad:  tf.Tensor(0.0020884292, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 668: 0.16079898\n",
      "grad:  tf.Tensor(0.0012687227, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 670: 0.16074519\n",
      "grad:  tf.Tensor(0.0006752982, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 672: 0.16063274\n",
      "grad:  tf.Tensor(0.0019491634, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 674: 0.15982218\n",
      "grad:  tf.Tensor(0.007697065, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 676: 0.16027698\n",
      "grad:  tf.Tensor(0.005038234, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 678: 0.16046657\n",
      "grad:  tf.Tensor(0.00095285854, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 680: 0.16044873\n",
      "grad:  tf.Tensor(0.00039975226, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 682: 0.16046253\n",
      "grad:  tf.Tensor(0.0003512913, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 684: 0.16034709\n",
      "grad:  tf.Tensor(0.00046256458, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 686: 0.16028245\n",
      "grad:  tf.Tensor(0.0029136806, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 688: 0.16031255\n",
      "grad:  tf.Tensor(0.0008144343, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 690: 0.16031888\n",
      "grad:  tf.Tensor(0.0041989023, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 692: 0.16030237\n",
      "grad:  tf.Tensor(0.0049753203, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 694: 0.15983178\n",
      "grad:  tf.Tensor(0.011603099, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 696: 0.16038075\n",
      "grad:  tf.Tensor(0.0002851862, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 698: 0.16028997\n",
      "grad:  tf.Tensor(0.00075423083, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 700: 0.16035762\n",
      "grad:  tf.Tensor(0.000355343, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 702: 0.16034871\n",
      "grad:  tf.Tensor(0.0003464734, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 704: 0.16031387\n",
      "grad:  tf.Tensor(0.00044480374, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 706: 0.16025743\n",
      "grad:  tf.Tensor(0.00046488477, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 708: 0.16033353\n",
      "grad:  tf.Tensor(0.0003946868, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 710: 0.16034895\n",
      "grad:  tf.Tensor(0.0008552352, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 712: 0.16032663\n",
      "grad:  tf.Tensor(0.00069620454, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 714: 0.16041358\n",
      "grad:  tf.Tensor(0.00029190653, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 716: 0.16043614\n",
      "grad:  tf.Tensor(0.00030970122, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 718: 0.16029097\n",
      "grad:  tf.Tensor(0.00086127775, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 720: 0.16006741\n",
      "grad:  tf.Tensor(0.0077031525, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 722: 0.16001001\n",
      "grad:  tf.Tensor(0.0023757303, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 724: 0.16020407\n",
      "grad:  tf.Tensor(0.0009738506, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 726: 0.15998150\n",
      "grad:  tf.Tensor(0.0027284774, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 728: 0.16045150\n",
      "grad:  tf.Tensor(0.0011592176, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 730: 0.16063568\n",
      "grad:  tf.Tensor(0.00025610626, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 732: 0.16122080\n",
      "grad:  tf.Tensor(0.00066455273, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 734: 0.16185375\n",
      "grad:  tf.Tensor(0.00045226247, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 736: 0.16234481\n",
      "grad:  tf.Tensor(0.0010757603, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 738: 0.16187875\n",
      "grad:  tf.Tensor(0.0017337503, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 740: 0.16149761\n",
      "grad:  tf.Tensor(0.0014705848, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 742: 0.16098982\n",
      "grad:  tf.Tensor(0.0012709902, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 744: 0.16101888\n",
      "grad:  tf.Tensor(0.0046310257, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 746: 0.16062112\n",
      "grad:  tf.Tensor(0.008372949, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 748: 0.16076358\n",
      "grad:  tf.Tensor(0.0010445944, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 750: 0.16067329\n",
      "grad:  tf.Tensor(0.00066250475, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 752: 0.16066095\n",
      "grad:  tf.Tensor(0.00032351355, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 754: 0.16059813\n",
      "grad:  tf.Tensor(0.00043971158, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 756: 0.16060361\n",
      "grad:  tf.Tensor(0.00017537901, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 758: 0.16059671\n",
      "grad:  tf.Tensor(0.00026585194, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 760: 0.16050009\n",
      "grad:  tf.Tensor(0.0017288924, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 762: 0.16047813\n",
      "grad:  tf.Tensor(0.0014450104, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 764: 0.16058302\n",
      "grad:  tf.Tensor(0.00030471702, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 766: 0.16057305\n",
      "grad:  tf.Tensor(0.00042347598, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 768: 0.16067185\n",
      "grad:  tf.Tensor(0.0001894685, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 770: 0.15890445\n",
      "grad:  tf.Tensor(0.0213056, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 772: 0.15977144\n",
      "grad:  tf.Tensor(0.0029144806, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 774: 0.16045932\n",
      "grad:  tf.Tensor(0.00061146467, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 776: 0.16031113\n",
      "grad:  tf.Tensor(0.0011556117, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 778: 0.16044958\n",
      "grad:  tf.Tensor(0.00058499316, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 780: 0.16014600\n",
      "grad:  tf.Tensor(0.0012844659, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 782: 0.16046000\n",
      "grad:  tf.Tensor(0.00031724945, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 784: 0.16033551\n",
      "grad:  tf.Tensor(0.00040973953, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 786: 0.16032112\n",
      "grad:  tf.Tensor(0.0015192657, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 788: 0.16036724\n",
      "grad:  tf.Tensor(0.0009639619, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 790: 0.16030285\n",
      "grad:  tf.Tensor(0.0008322817, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 792: 0.15950657\n",
      "grad:  tf.Tensor(0.014058714, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 794: 0.16006526\n",
      "grad:  tf.Tensor(0.0031080216, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 796: 0.16022286\n",
      "grad:  tf.Tensor(0.0026475738, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 798: 0.16032606\n",
      "grad:  tf.Tensor(0.0013682405, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 800: 0.15873316\n",
      "grad:  tf.Tensor(0.02886444, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 802: 0.15758249\n",
      "grad:  tf.Tensor(0.0630757, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 804: 0.16043465\n",
      "grad:  tf.Tensor(0.00087951904, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 806: 0.16088115\n",
      "grad:  tf.Tensor(0.0005069564, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 808: 0.16440082\n",
      "grad:  tf.Tensor(0.0008059289, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 810: 0.16637383\n",
      "grad:  tf.Tensor(0.0027528226, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 812: 0.16343394\n",
      "grad:  tf.Tensor(0.0019124283, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 814: 0.16294862\n",
      "grad:  tf.Tensor(0.0013535476, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 816: 0.16243096\n",
      "grad:  tf.Tensor(0.00033170293, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 818: 0.16190700\n",
      "grad:  tf.Tensor(0.00050117227, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 820: 0.16142370\n",
      "grad:  tf.Tensor(0.0019561104, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 822: 0.16107854\n",
      "grad:  tf.Tensor(0.0006260414, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 824: 0.16080576\n",
      "grad:  tf.Tensor(0.0017401716, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 826: 0.16080925\n",
      "grad:  tf.Tensor(0.00023287104, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 828: 0.16075094\n",
      "grad:  tf.Tensor(0.0002953444, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 830: 0.16060382\n",
      "grad:  tf.Tensor(0.00025035028, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 832: 0.16062337\n",
      "grad:  tf.Tensor(0.00061333756, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 834: 0.16061631\n",
      "grad:  tf.Tensor(0.0003189507, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 836: 0.16061211\n",
      "grad:  tf.Tensor(0.00026654135, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 838: 0.16059744\n",
      "grad:  tf.Tensor(0.00062416727, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 840: 0.15999660\n",
      "grad:  tf.Tensor(0.0074586873, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 842: 0.16078243\n",
      "grad:  tf.Tensor(0.001043165, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 844: 0.16108489\n",
      "grad:  tf.Tensor(0.005642306, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 846: 0.16123299\n",
      "grad:  tf.Tensor(0.00066889846, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 848: 0.16088001\n",
      "grad:  tf.Tensor(0.0009962161, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 850: 0.16077706\n",
      "grad:  tf.Tensor(0.0004106671, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 852: 0.16060963\n",
      "grad:  tf.Tensor(0.00042178595, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 854: 0.16044290\n",
      "grad:  tf.Tensor(0.0019491006, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 856: 0.16051315\n",
      "grad:  tf.Tensor(0.00022322917, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 858: 0.16051699\n",
      "grad:  tf.Tensor(0.00033943393, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 860: 0.16046272\n",
      "grad:  tf.Tensor(0.00028430173, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 862: 0.16043854\n",
      "grad:  tf.Tensor(0.00069917063, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 864: 0.16046920\n",
      "grad:  tf.Tensor(0.0005548496, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 866: 0.16047288\n",
      "grad:  tf.Tensor(0.00018131491, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 868: 0.16047516\n",
      "grad:  tf.Tensor(0.0002998084, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 870: 0.16046159\n",
      "grad:  tf.Tensor(0.00041160107, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 872: 0.16026175\n",
      "grad:  tf.Tensor(0.0025425346, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 874: 0.16015889\n",
      "grad:  tf.Tensor(0.0050080735, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 876: 0.16045856\n",
      "grad:  tf.Tensor(0.0009374981, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 878: 0.16042317\n",
      "grad:  tf.Tensor(0.001421547, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 880: 0.16043113\n",
      "grad:  tf.Tensor(0.0018057768, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 882: 0.16033401\n",
      "grad:  tf.Tensor(0.004493176, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 884: 0.16056451\n",
      "grad:  tf.Tensor(0.0016878034, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 886: 0.16067317\n",
      "grad:  tf.Tensor(0.0011436725, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 888: 0.16092253\n",
      "grad:  tf.Tensor(0.0006151629, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 890: 0.16078706\n",
      "grad:  tf.Tensor(0.0036470373, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 892: 0.16048278\n",
      "grad:  tf.Tensor(0.0032835852, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 894: 0.16056874\n",
      "grad:  tf.Tensor(0.0005605315, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 896: 0.16007520\n",
      "grad:  tf.Tensor(0.013263281, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 898: 0.16155222\n",
      "grad:  tf.Tensor(0.00058117614, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 900: 0.16136625\n",
      "grad:  tf.Tensor(0.0024427841, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 902: 0.16040511\n",
      "grad:  tf.Tensor(0.002996931, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 904: 0.16038410\n",
      "grad:  tf.Tensor(0.0023211522, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 906: 0.16041043\n",
      "grad:  tf.Tensor(0.00033126798, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 908: 0.16040896\n",
      "grad:  tf.Tensor(0.00094279984, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 910: 0.16038822\n",
      "grad:  tf.Tensor(0.0005335347, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 912: 0.16044645\n",
      "grad:  tf.Tensor(0.0004271996, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 914: 0.16051498\n",
      "grad:  tf.Tensor(0.00057580107, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 916: 0.16044411\n",
      "grad:  tf.Tensor(0.00083864544, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 918: 0.16051635\n",
      "grad:  tf.Tensor(0.00081951165, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 920: 0.16049033\n",
      "grad:  tf.Tensor(0.0002962996, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 922: 0.16028079\n",
      "grad:  tf.Tensor(0.0035719476, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 924: 0.16037445\n",
      "grad:  tf.Tensor(0.0017375703, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 926: 0.16041675\n",
      "grad:  tf.Tensor(0.0007844149, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 928: 0.16040760\n",
      "grad:  tf.Tensor(0.00032574253, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 930: 0.16038983\n",
      "grad:  tf.Tensor(0.0002857864, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 932: 0.16038820\n",
      "grad:  tf.Tensor(0.00034218415, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 934: 0.16020671\n",
      "grad:  tf.Tensor(0.00055210653, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 936: 0.16013874\n",
      "grad:  tf.Tensor(0.005488483, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 938: 0.15988876\n",
      "grad:  tf.Tensor(0.0023334438, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 940: 0.16028167\n",
      "grad:  tf.Tensor(0.00038566353, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 942: 0.16031678\n",
      "grad:  tf.Tensor(0.00029997795, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 944: 0.16032793\n",
      "grad:  tf.Tensor(0.0012852093, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 946: 0.16025135\n",
      "grad:  tf.Tensor(0.0022312775, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 948: 0.15914421\n",
      "grad:  tf.Tensor(0.02067722, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 950: 0.16031750\n",
      "grad:  tf.Tensor(0.00072202185, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 952: 0.16055821\n",
      "grad:  tf.Tensor(0.00040132596, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 954: 0.16059078\n",
      "grad:  tf.Tensor(0.0020360702, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 956: 0.16103664\n",
      "grad:  tf.Tensor(0.0016339625, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 958: 0.16160166\n",
      "grad:  tf.Tensor(0.0002759742, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 960: 0.16260663\n",
      "grad:  tf.Tensor(0.002856897, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 962: 0.16135311\n",
      "grad:  tf.Tensor(0.000463617, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 964: 0.16112821\n",
      "grad:  tf.Tensor(0.00038601735, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 966: 0.16095042\n",
      "grad:  tf.Tensor(0.0012013512, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 968: 0.16124536\n",
      "grad:  tf.Tensor(0.0020528766, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 970: 0.16080913\n",
      "grad:  tf.Tensor(0.0016766553, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 972: 0.16060515\n",
      "grad:  tf.Tensor(0.0008135972, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 974: 0.16062312\n",
      "grad:  tf.Tensor(0.00030530847, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 976: 0.16054992\n",
      "grad:  tf.Tensor(0.00037536438, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 978: 0.16051583\n",
      "grad:  tf.Tensor(0.00047763638, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 980: 0.16049017\n",
      "grad:  tf.Tensor(0.00025330778, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 982: 0.16039814\n",
      "grad:  tf.Tensor(0.0015821424, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 984: 0.16043244\n",
      "grad:  tf.Tensor(0.0008623305, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 986: 0.16026203\n",
      "grad:  tf.Tensor(0.0041334108, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 988: 0.16042970\n",
      "grad:  tf.Tensor(0.0002481984, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 990: 0.16045170\n",
      "grad:  tf.Tensor(0.00020028173, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 992: 0.16046849\n",
      "grad:  tf.Tensor(0.00045005872, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 994: 0.16047478\n",
      "grad:  tf.Tensor(0.0004996046, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 996: 0.16048454\n",
      "grad:  tf.Tensor(0.0003169318, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 998: 0.15970080\n",
      "grad:  tf.Tensor(0.011376522, shape=(), dtype=float32)\n",
      "Training loss (for one batch) at step 1000: 0.16057462\n",
      "grad:  tf.Tensor(0.0005166882, shape=(), dtype=float32)\n",
      "[{'num_tirage': 0, 'epochs': 1000, 'time_train': 246.38424444198608, 'norme_grad': 0.0005166882, 'cost_train': 0.16057462, 'cost_test': 0.16067164, 'prop_entropie': 0, 'categorical_accuracy_train': 0.1960333287715912, 'loss_train': 0.0, 'categorical_accuracy': 0.19629999995231628, 'loss': 0.0, 'temps_forward': 2.1463632583618163e-06}]\n"
     ]
    }
   ],
   "source": [
    "# Qqs paramètres secondaires\n",
    "tirageMin=0; nbTirages=1;\n",
    "\n",
    "# si =1, tous les exemples ont les mêmes poids\n",
    "sample_weight=1\n",
    "\n",
    "# Algorithme adaptatif de la thèse de Bilel Bensaid\n",
    "algo=\"Adam\"     \n",
    "# Lancement de l'apprentissage\n",
    "studies = tirages.tirages(tirageMin,nbTirages,name_model,nbNeurons,activations,loss,name_init,params_init,metrics,\n",
    "x_train,y_train,algo,eps,max_epochs,lr,seuil,f1,f2,rho,eps_egd,lambd,beta_1,beta_2,epsilon,amsgrad,sample_weight,\n",
    "\"simple\",x_test,y_test)\n",
    "print(studies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3562197",
   "metadata": {},
   "source": [
    "## Apprentissage avec l'optimiseur de la thèse de Bilel Bensaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b668853e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost_init:  tf.Tensor(0.119567335, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at epoch 2: 0.10738212\n",
      "grad:  tf.Tensor(0.2253113, shape=(), dtype=float32)\n",
      "lr:  2028.6020648339486\n",
      "dim:  tf.Tensor(-0.0059922934, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-51.491173, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at epoch 4: 0.09965721\n",
      "grad:  tf.Tensor(0.24199158, shape=(), dtype=float32)\n",
      "lr:  5456.955757827525\n",
      "dim:  tf.Tensor(-0.005275026, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-159.77945, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at epoch 6: 0.09513728\n",
      "grad:  tf.Tensor(0.1349662, shape=(), dtype=float32)\n",
      "lr:  1145.1518032108636\n",
      "dim:  tf.Tensor(-0.0016312152, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-10.429971, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at epoch 8: 0.09225729\n",
      "grad:  tf.Tensor(0.10907527, shape=(), dtype=float32)\n",
      "lr:  860.3915972377324\n",
      "dim:  tf.Tensor(-0.0012452975, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-5.118218, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at epoch 10: 0.08754788\n",
      "grad:  tf.Tensor(0.09433823, shape=(), dtype=float32)\n",
      "lr:  646.4415447119425\n",
      "dim:  tf.Tensor(-0.0015730709, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-2.8765683, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one batch) at epoch 12: 0.07168628\n",
      "grad:  tf.Tensor(0.1194011, shape=(), dtype=float32)\n",
      "lr:  1136.6916561733465\n",
      "dim:  tf.Tensor(-0.0036364794, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-8.102692, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one batch) at epoch 14: 0.06765378\n",
      "grad:  tf.Tensor(0.10024209, shape=(), dtype=float32)\n",
      "lr:  1306.5195961165757\n",
      "dim:  tf.Tensor(-0.0014502406, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-6.564266, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one batch) at epoch 16: 0.06464054\n",
      "grad:  tf.Tensor(0.1295797, shape=(), dtype=float32)\n",
      "lr:  1501.7207575739449\n",
      "dim:  tf.Tensor(-0.0016355291, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-12.607618, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one batch) at epoch 18: 0.06189548\n",
      "grad:  tf.Tensor(0.1017963, shape=(), dtype=float32)\n",
      "lr:  1726.0860383813522\n",
      "dim:  tf.Tensor(-0.0013858043, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-8.943272, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one batch) at epoch 20: 0.06029960\n",
      "grad:  tf.Tensor(0.073764876, shape=(), dtype=float32)\n",
      "lr:  1296.8672968672079\n",
      "dim:  tf.Tensor(-0.00069832057, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-3.528294, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one batch) at epoch 22: 0.05887646\n",
      "grad:  tf.Tensor(0.059272677, shape=(), dtype=float32)\n",
      "lr:  974.3806208297917\n",
      "dim:  tf.Tensor(-0.0005796924, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-1.7116215, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one batch) at epoch 24: 0.05662249\n",
      "grad:  tf.Tensor(0.048044626, shape=(), dtype=float32)\n",
      "lr:  732.0853849442593\n",
      "dim:  tf.Tensor(-0.0007863082, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.84493124, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one batch) at epoch 26: 0.05488662\n",
      "grad:  tf.Tensor(0.04772682, shape=(), dtype=float32)\n",
      "lr:  550.0407124195114\n",
      "dim:  tf.Tensor(-0.00055402145, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.62645495, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one batch) at epoch 28: 0.05429085\n",
      "grad:  tf.Tensor(0.04445184, shape=(), dtype=float32)\n",
      "lr:  967.1820963201023\n",
      "dim:  tf.Tensor(-0.00028116629, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.9555595, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one batch) at epoch 30: 0.05370291\n",
      "grad:  tf.Tensor(0.03843042, shape=(), dtype=float32)\n",
      "lr:  726.6768880242172\n",
      "dim:  tf.Tensor(-0.0002557449, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.53661346, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one batch) at epoch 32: 0.04415167\n",
      "grad:  tf.Tensor(0.045761827, shape=(), dtype=float32)\n",
      "lr:  1954.7666331043258\n",
      "dim:  tf.Tensor(-0.00045193732, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-2.0467823, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one batch) at epoch 34: 0.04389751\n",
      "grad:  tf.Tensor(0.038252193, shape=(), dtype=float32)\n",
      "lr:  2246.8194414159966\n",
      "dim:  tf.Tensor(-0.00012466684, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-1.6438072, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one batch) at epoch 36: 0.04336303\n",
      "grad:  tf.Tensor(0.08375513, shape=(), dtype=float32)\n",
      "lr:  14144.970835448406\n",
      "dim:  tf.Tensor(-0.00045434758, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-49.61293, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one batch) at epoch 38: 0.04301785\n",
      "grad:  tf.Tensor(0.03200036, shape=(), dtype=float32)\n",
      "lr:  1940.3252174826341\n",
      "dim:  tf.Tensor(-7.2948635e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.99346876, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss (for one batch) at epoch 40: 0.04289680\n",
      "grad:  tf.Tensor(0.024892123, shape=(), dtype=float32)\n",
      "lr:  1457.8324972720934\n",
      "dim:  tf.Tensor(-6.0088933e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.4516495, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss (for one batch) at epoch 42: 0.04277227\n",
      "grad:  tf.Tensor(0.024110677, shape=(), dtype=float32)\n",
      "lr:  1095.3192644993335\n",
      "dim:  tf.Tensor(-6.006658e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.31836808, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss (for one batch) at epoch 44: 0.04264505\n",
      "grad:  tf.Tensor(0.020320972, shape=(), dtype=float32)\n",
      "lr:  822.950711709537\n",
      "dim:  tf.Tensor(-6.0964376e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.16991541, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss (for one batch) at epoch 46: 0.04208856\n",
      "grad:  tf.Tensor(0.023111587, shape=(), dtype=float32)\n",
      "lr:  618.3109307520497\n",
      "dim:  tf.Tensor(-0.0002425313, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.16513398, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss (for one batch) at epoch 48: 0.04198016\n",
      "grad:  tf.Tensor(0.022701923, shape=(), dtype=float32)\n",
      "lr:  1087.227270053961\n",
      "dim:  tf.Tensor(-5.1293522e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.28016615, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss (for one batch) at epoch 50: 0.04187465\n",
      "grad:  tf.Tensor(0.0294613, shape=(), dtype=float32)\n",
      "lr:  1911.7616686983827\n",
      "dim:  tf.Tensor(-5.4907054e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.8296742, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss (for one batch) at epoch 52: 0.04176609\n",
      "grad:  tf.Tensor(0.03170769, shape=(), dtype=float32)\n",
      "lr:  2197.3893005140976\n",
      "dim:  tf.Tensor(-5.7533383e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-1.1046029, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss (for one batch) at epoch 54: 0.04142746\n",
      "grad:  tf.Tensor(0.07125334, shape=(), dtype=float32)\n",
      "lr:  13833.7807644702\n",
      "dim:  tf.Tensor(-0.0002876632, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-35.117317, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss (for one batch) at epoch 56: 0.04118610\n",
      "grad:  tf.Tensor(0.026360944, shape=(), dtype=float32)\n",
      "lr:  1897.6379649479013\n",
      "dim:  tf.Tensor(-5.0894916e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.6593337, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss (for one batch) at epoch 58: 0.04108960\n",
      "grad:  tf.Tensor(0.028584484, shape=(), dtype=float32)\n",
      "lr:  2181.1554383057046\n",
      "dim:  tf.Tensor(-5.3711236e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.8910814, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss (for one batch) at epoch 60: 0.04080259\n",
      "grad:  tf.Tensor(0.0718684, shape=(), dtype=float32)\n",
      "lr:  13731.579624827355\n",
      "dim:  tf.Tensor(-0.00024508685, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-35.46226, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss (for one batch) at epoch 62: 0.04055904\n",
      "grad:  tf.Tensor(0.029747153, shape=(), dtype=float32)\n",
      "lr:  2881.5962353641644\n",
      "dim:  tf.Tensor(-6.183237e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-1.2749523, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss (for one batch) at epoch 64: 0.03693670\n",
      "grad:  tf.Tensor(0.08098606, shape=(), dtype=float32)\n",
      "lr:  232545.50669490345\n",
      "dim:  tf.Tensor(-0.003581494, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-762.60297, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss (for one batch) at epoch 66: 0.03642086\n",
      "grad:  tf.Tensor(0.030550614, shape=(), dtype=float32)\n",
      "lr:  2488.51053138315\n",
      "dim:  tf.Tensor(-0.00020525232, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-1.1613132, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss (for one batch) at epoch 68: 0.03626781\n",
      "grad:  tf.Tensor(0.034777213, shape=(), dtype=float32)\n",
      "lr:  4375.753972593447\n",
      "dim:  tf.Tensor(-9.7136945e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-2.6461377, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss (for one batch) at epoch 70: 0.03600468\n",
      "grad:  tf.Tensor(0.034452848, shape=(), dtype=float32)\n",
      "lr:  18007.217994211718\n",
      "dim:  tf.Tensor(-0.00021319464, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-10.687273, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss (for one batch) at epoch 72: 0.03590432\n",
      "grad:  tf.Tensor(0.012793494, shape=(), dtype=float32)\n",
      "lr:  2470.1259251319225\n",
      "dim:  tf.Tensor(-3.8534403e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.20214708, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss (for one batch) at epoch 74: 0.03586633\n",
      "grad:  tf.Tensor(0.011954187, shape=(), dtype=float32)\n",
      "lr:  1213.1431100736922\n",
      "dim:  tf.Tensor(-1.6029924e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.08668065, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss (for one batch) at epoch 76: 0.03583027\n",
      "grad:  tf.Tensor(0.010727953, shape=(), dtype=float32)\n",
      "lr:  911.4757844572482\n",
      "dim:  tf.Tensor(-1.6391277e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.052450407, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss (for one batch) at epoch 78: 0.03577951\n",
      "grad:  tf.Tensor(0.0099234255, shape=(), dtype=float32)\n",
      "lr:  684.8228364430062\n",
      "dim:  tf.Tensor(-1.8462539e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.03371875, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss (for one batch) at epoch 80: 0.03541224\n",
      "grad:  tf.Tensor(0.020237131, shape=(), dtype=float32)\n",
      "lr:  514.5307481680459\n",
      "dim:  tf.Tensor(-0.000110615045, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.10536084, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss (for one batch) at epoch 82: 0.03531013\n",
      "grad:  tf.Tensor(0.038035154, shape=(), dtype=float32)\n",
      "lr:  17742.133540836618\n",
      "dim:  tf.Tensor(-8.431822e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-12.833531, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss (for one batch) at epoch 84: 0.03522963\n",
      "grad:  tf.Tensor(0.016589094, shape=(), dtype=float32)\n",
      "lr:  3723.218057605363\n",
      "dim:  tf.Tensor(-2.0172447e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.51231116, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss (for one batch) at epoch 86: 0.03513726\n",
      "grad:  tf.Tensor(0.032094337, shape=(), dtype=float32)\n",
      "lr:  15321.885010721662\n",
      "dim:  tf.Tensor(-7.6554716e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-7.8911266, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss (for one batch) at epoch 88: 0.03507822\n",
      "grad:  tf.Tensor(0.015214812, shape=(), dtype=float32)\n",
      "lr:  3215.324629203633\n",
      "dim:  tf.Tensor(-1.7739832e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.37215856, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss (for one batch) at epoch 90: 0.03505106\n",
      "grad:  tf.Tensor(0.01484733, shape=(), dtype=float32)\n",
      "lr:  2415.7830303384962\n",
      "dim:  tf.Tensor(-1.3086945e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.26627147, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss (for one batch) at epoch 92: 0.03500019\n",
      "grad:  tf.Tensor(0.030699996, shape=(), dtype=float32)\n",
      "lr:  9941.493952010274\n",
      "dim:  tf.Tensor(-3.8981438e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-4.6848783, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss (for one batch) at epoch 94: 0.03493813\n",
      "grad:  tf.Tensor(0.018562166, shape=(), dtype=float32)\n",
      "lr:  4882.526339654699\n",
      "dim:  tf.Tensor(-2.4992973e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.84114707, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss (for one batch) at epoch 96: 0.03464176\n",
      "grad:  tf.Tensor(0.07903901, shape=(), dtype=float32)\n",
      "lr:  71938.07159919284\n",
      "dim:  tf.Tensor(-0.000280831, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-224.70448, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss (for one batch) at epoch 98: 0.03440042\n",
      "grad:  tf.Tensor(0.009335549, shape=(), dtype=float32)\n",
      "lr:  769.8220074269447\n",
      "dim:  tf.Tensor(-1.8555671e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.033545945, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss (for one batch) at epoch 100: 0.03409956\n",
      "grad:  tf.Tensor(0.01839651, shape=(), dtype=float32)\n",
      "lr:  884.8376186828631\n",
      "dim:  tf.Tensor(-0.00014812127, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.14972849, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss (for one batch) at epoch 102: 0.03398243\n",
      "grad:  tf.Tensor(0.02652763, shape=(), dtype=float32)\n",
      "lr:  2380.2202618822066\n",
      "dim:  tf.Tensor(-5.5924058e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.8374985, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss (for one batch) at epoch 104: 0.03375179\n",
      "grad:  tf.Tensor(0.069058865, shape=(), dtype=float32)\n",
      "lr:  6402.8115164316605\n",
      "dim:  tf.Tensor(-0.00017086044, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-15.26791, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss (for one batch) at epoch 106: 0.03305042\n",
      "grad:  tf.Tensor(0.100120224, shape=(), dtype=float32)\n",
      "lr:  4810.65061591698\n",
      "dim:  tf.Tensor(-0.00045285746, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-24.111122, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss (for one batch) at epoch 108: 0.03137213\n",
      "grad:  tf.Tensor(0.070635624, shape=(), dtype=float32)\n",
      "lr:  5529.388084825804\n",
      "dim:  tf.Tensor(-0.0011802502, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-13.794141, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss (for one batch) at epoch 110: 0.03026991\n",
      "grad:  tf.Tensor(0.051275942, shape=(), dtype=float32)\n",
      "lr:  2715.626353207778\n",
      "dim:  tf.Tensor(-0.0005391091, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-3.5699928, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss (for one batch) at epoch 112: 0.02964368\n",
      "grad:  tf.Tensor(0.042356715, shape=(), dtype=float32)\n",
      "lr:  1333.7147577820813\n",
      "dim:  tf.Tensor(-0.00024081767, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-1.196403, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss (for one batch) at epoch 114: 0.02916493\n",
      "grad:  tf.Tensor(0.035045445, shape=(), dtype=float32)\n",
      "lr:  1002.0653746430517\n",
      "dim:  tf.Tensor(-0.00020512566, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.6153599, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss (for one batch) at epoch 116: 0.02862070\n",
      "grad:  tf.Tensor(0.028240852, shape=(), dtype=float32)\n",
      "lr:  752.8858844812958\n",
      "dim:  tf.Tensor(-0.00020460598, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.30023044, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss (for one batch) at epoch 118: 0.02744057\n",
      "grad:  tf.Tensor(0.031607237, shape=(), dtype=float32)\n",
      "lr:  565.6688369789224\n",
      "dim:  tf.Tensor(-0.0003549084, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.2825565, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss (for one batch) at epoch 120: 0.02661453\n",
      "grad:  tf.Tensor(0.07971128, shape=(), dtype=float32)\n",
      "lr:  45649.6106923031\n",
      "dim:  tf.Tensor(-0.0007760618, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-145.02626, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss (for one batch) at epoch 122: 0.02629384\n",
      "grad:  tf.Tensor(0.017944977, shape=(), dtype=float32)\n",
      "lr:  1748.997059453834\n",
      "dim:  tf.Tensor(-4.6098605e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.28160793, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss (for one batch) at epoch 124: 0.02624785\n",
      "grad:  tf.Tensor(0.014032726, shape=(), dtype=float32)\n",
      "lr:  1314.081128220945\n",
      "dim:  tf.Tensor(-2.0932406e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.12938273, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss (for one batch) at epoch 126: 0.02620691\n",
      "grad:  tf.Tensor(0.014587274, shape=(), dtype=float32)\n",
      "lr:  1510.412023861833\n",
      "dim:  tf.Tensor(-1.9468367e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.16069919, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss (for one batch) at epoch 128: 0.02616430\n",
      "grad:  tf.Tensor(0.018931722, shape=(), dtype=float32)\n",
      "lr:  2655.8824366288054\n",
      "dim:  tf.Tensor(-2.4555251e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.47594756, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss (for one batch) at epoch 130: 0.02610411\n",
      "grad:  tf.Tensor(0.022713484, shape=(), dtype=float32)\n",
      "lr:  4670.05784233522\n",
      "dim:  tf.Tensor(-3.9739534e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-1.2046468, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss (for one batch) at epoch 132: 0.02576162\n",
      "grad:  tf.Tensor(0.06430973, shape=(), dtype=float32)\n",
      "lr:  44977.60227317661\n",
      "dim:  tf.Tensor(-0.00031834655, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-93.007866, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss (for one batch) at epoch 134: 0.02559302\n",
      "grad:  tf.Tensor(0.009380283, shape=(), dtype=float32)\n",
      "lr:  736.3223570936625\n",
      "dim:  tf.Tensor(-1.9270927e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.03239439, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss (for one batch) at epoch 136: 0.02524171\n",
      "grad:  tf.Tensor(0.020700509, shape=(), dtype=float32)\n",
      "lr:  553.2240940680011\n",
      "dim:  tf.Tensor(-0.00012573972, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.11853133, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss (for one batch) at epoch 138: 0.02515466\n",
      "grad:  tf.Tensor(0.025022557, shape=(), dtype=float32)\n",
      "lr:  12469.68377269153\n",
      "dim:  tf.Tensor(-6.718002e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-3.9038112, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss (for one batch) at epoch 140: 0.02508719\n",
      "grad:  tf.Tensor(0.023477716, shape=(), dtype=float32)\n",
      "lr:  9368.898610780894\n",
      "dim:  tf.Tensor(-3.8485974e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-2.5820832, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss (for one batch) at epoch 142: 0.02503668\n",
      "grad:  tf.Tensor(0.01790316, shape=(), dtype=float32)\n",
      "lr:  4601.309869674282\n",
      "dim:  tf.Tensor(-1.9868836e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.7374132, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss (for one batch) at epoch 144: 0.02499645\n",
      "grad:  tf.Tensor(0.016171426, shape=(), dtype=float32)\n",
      "lr:  5288.770688061837\n",
      "dim:  tf.Tensor(-2.45478e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.69154644, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss (for one batch) at epoch 146: 0.02496651\n",
      "grad:  tf.Tensor(0.013193262, shape=(), dtype=float32)\n",
      "lr:  2597.452889224364\n",
      "dim:  tf.Tensor(-1.2874603e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.22605912, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss (for one batch) at epoch 148: 0.02491630\n",
      "grad:  tf.Tensor(0.026806228, shape=(), dtype=float32)\n",
      "lr:  10689.106540017954\n",
      "dim:  tf.Tensor(-3.9795414e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-3.8404562, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss (for one batch) at epoch 150: 0.02486258\n",
      "grad:  tf.Tensor(0.016686443, shape=(), dtype=float32)\n",
      "lr:  5249.698333162457\n",
      "dim:  tf.Tensor(-2.3044646e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.7308561, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss (for one batch) at epoch 152: 0.02467101\n",
      "grad:  tf.Tensor(0.047560424, shape=(), dtype=float32)\n",
      "lr:  50560.15399695138\n",
      "dim:  tf.Tensor(-0.0001777932, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-57.18338, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss (for one batch) at epoch 154: 0.02454719\n",
      "grad:  tf.Tensor(0.007704096, shape=(), dtype=float32)\n",
      "lr:  1266.2522567473825\n",
      "dim:  tf.Tensor(-8.974224e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.03757799, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss (for one batch) at epoch 156: 0.02451130\n",
      "grad:  tf.Tensor(0.007688404, shape=(), dtype=float32)\n",
      "lr:  951.3784972734768\n",
      "dim:  tf.Tensor(-1.6190112e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.028118731, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss (for one batch) at epoch 158: 0.02448447\n",
      "grad:  tf.Tensor(0.007283287, shape=(), dtype=float32)\n",
      "lr:  714.8031051879977\n",
      "dim:  tf.Tensor(-1.0136515e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.01895882, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss (for one batch) at epoch 160: 0.02441958\n",
      "grad:  tf.Tensor(0.007164005, shape=(), dtype=float32)\n",
      "lr:  821.5985920377652\n",
      "dim:  tf.Tensor(-2.3487955e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.02108344, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss (for one batch) at epoch 162: 0.02431402\n",
      "grad:  tf.Tensor(0.008831653, shape=(), dtype=float32)\n",
      "lr:  944.34990774264\n",
      "dim:  tf.Tensor(-3.5259873e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.036828745, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss (for one batch) at epoch 164: 0.02429037\n",
      "grad:  tf.Tensor(0.0076214904, shape=(), dtype=float32)\n",
      "lr:  1660.5285805346193\n",
      "dim:  tf.Tensor(-9.339303e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.048227657, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss (for one batch) at epoch 166: 0.02426037\n",
      "grad:  tf.Tensor(0.0071886135, shape=(), dtype=float32)\n",
      "lr:  1247.61174340308\n",
      "dim:  tf.Tensor(-1.4387071e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.032235894, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss (for one batch) at epoch 168: 0.02422880\n",
      "grad:  tf.Tensor(0.00694638, shape=(), dtype=float32)\n",
      "lr:  937.3732439920636\n",
      "dim:  tf.Tensor(-1.1129305e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.022615157, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss (for one batch) at epoch 170: 0.02415671\n",
      "grad:  tf.Tensor(0.009983847, shape=(), dtype=float32)\n",
      "lr:  704.2804808453325\n",
      "dim:  tf.Tensor(-3.2657757e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.035100352, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss (for one batch) at epoch 172: 0.02413436\n",
      "grad:  tf.Tensor(0.013526253, shape=(), dtype=float32)\n",
      "lr:  4433.835081671945\n",
      "dim:  tf.Tensor(-1.35507435e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.40560618, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss (for one batch) at epoch 174: 0.02411239\n",
      "grad:  tf.Tensor(0.011375933, shape=(), dtype=float32)\n",
      "lr:  3331.2914821529293\n",
      "dim:  tf.Tensor(-1.13248825e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.21555431, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss (for one batch) at epoch 176: 0.02300956\n",
      "grad:  tf.Tensor(0.09116894, shape=(), dtype=float32)\n",
      "lr:  411270.5533522134\n",
      "dim:  tf.Tensor(-0.0010958128, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-1709.1943, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss (for one batch) at epoch 178: 0.02263501\n",
      "grad:  tf.Tensor(0.007506182, shape=(), dtype=float32)\n",
      "lr:  803.523381622268\n",
      "dim:  tf.Tensor(-4.1980296e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.022636365, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss (for one batch) at epoch 180: 0.02262137\n",
      "grad:  tf.Tensor(0.007746878, shape=(), dtype=float32)\n",
      "lr:  3306.6805828076867\n",
      "dim:  tf.Tensor(-7.5027347e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.09922377, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss (for one batch) at epoch 182: 0.02260385\n",
      "grad:  tf.Tensor(0.015726548, shape=(), dtype=float32)\n",
      "lr:  8894.997179807126\n",
      "dim:  tf.Tensor(-1.280196e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-1.0999744, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss (for one batch) at epoch 184: 0.02255146\n",
      "grad:  tf.Tensor(0.020426309, shape=(), dtype=float32)\n",
      "lr:  23927.613462318608\n",
      "dim:  tf.Tensor(-4.0164217e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-4.991708, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss (for one batch) at epoch 186: 0.02252813\n",
      "grad:  tf.Tensor(0.0054289666, shape=(), dtype=float32)\n",
      "lr:  1402.4634192757678\n",
      "dim:  tf.Tensor(-4.6435744e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.020667877, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss (for one batch) at epoch 188: 0.02251515\n",
      "grad:  tf.Tensor(0.00509222, shape=(), dtype=float32)\n",
      "lr:  1053.7185882210752\n",
      "dim:  tf.Tensor(-5.7127327e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.013661833, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss (for one batch) at epoch 190: 0.02249534\n",
      "grad:  tf.Tensor(0.004999662, shape=(), dtype=float32)\n",
      "lr:  791.6947051182171\n",
      "dim:  tf.Tensor(-7.793307e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.009894845, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss (for one batch) at epoch 192: 0.02246226\n",
      "grad:  tf.Tensor(0.0049728127, shape=(), dtype=float32)\n",
      "lr:  909.9782168374983\n",
      "dim:  tf.Tensor(-1.6219914e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.011251365, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss (for one batch) at epoch 194: 0.02241122\n",
      "grad:  tf.Tensor(0.008164189, shape=(), dtype=float32)\n",
      "lr:  1045.9339310537714\n",
      "dim:  tf.Tensor(-2.0319596e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.03485783, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss (for one batch) at epoch 196: 0.02239789\n",
      "grad:  tf.Tensor(0.005849053, shape=(), dtype=float32)\n",
      "lr:  1839.1521740255607\n",
      "dim:  tf.Tensor(-4.10527e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.031460006, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss (for one batch) at epoch 198: 0.02238943\n",
      "grad:  tf.Tensor(0.005779633, shape=(), dtype=float32)\n",
      "lr:  1381.8177399155918\n",
      "dim:  tf.Tensor(-4.1686e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.023079226, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss (for one batch) at epoch 200: 0.02238176\n",
      "grad:  tf.Tensor(0.0054734917, shape=(), dtype=float32)\n",
      "lr:  1588.268855195958\n",
      "dim:  tf.Tensor(-3.701076e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.02379156, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss (for one batch) at epoch 202: 0.02237203\n",
      "grad:  tf.Tensor(0.0053309184, shape=(), dtype=float32)\n",
      "lr:  1193.3205478377668\n",
      "dim:  tf.Tensor(-4.777685e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.016956303, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss (for one batch) at epoch 204: 0.02236171\n",
      "grad:  tf.Tensor(0.00466238, shape=(), dtype=float32)\n",
      "lr:  896.5824175379531\n",
      "dim:  tf.Tensor(-4.8894435e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.009744858, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss (for one batch) at epoch 206: 0.02064463\n",
      "grad:  tf.Tensor(0.028637398, shape=(), dtype=float32)\n",
      "lr:  673.6329420412242\n",
      "dim:  tf.Tensor(-0.0003585387, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.27622336, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss (for one batch) at epoch 208: 0.02059767\n",
      "grad:  tf.Tensor(0.00867643, shape=(), dtype=float32)\n",
      "lr:  4240.891877348782\n",
      "dim:  tf.Tensor(-6.550923e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.15962811, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss (for one batch) at epoch 210: 0.02055126\n",
      "grad:  tf.Tensor(0.023789195, shape=(), dtype=float32)\n",
      "lr:  40844.27957482394\n",
      "dim:  tf.Tensor(-4.168786e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-11.557416, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss (for one batch) at epoch 212: 0.02051913\n",
      "grad:  tf.Tensor(0.004927942, shape=(), dtype=float32)\n",
      "lr:  1564.8879319779646\n",
      "dim:  tf.Tensor(-4.5914203e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.019001348, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss (for one batch) at epoch 214: 0.02051323\n",
      "grad:  tf.Tensor(0.004550892, shape=(), dtype=float32)\n",
      "lr:  1798.6907335438002\n",
      "dim:  tf.Tensor(-2.7008355e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.018625997, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss (for one batch) at epoch 216: 0.02050783\n",
      "grad:  tf.Tensor(0.003997354, shape=(), dtype=float32)\n",
      "lr:  1351.4176800239416\n",
      "dim:  tf.Tensor(-2.4382025e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.010797042, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss (for one batch) at epoch 218: 0.02049770\n",
      "grad:  tf.Tensor(0.0036601396, shape=(), dtype=float32)\n",
      "lr:  1015.3661837591378\n",
      "dim:  tf.Tensor(-4.9099326e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.0068012387, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss (for one batch) at epoch 220: 0.02044656\n",
      "grad:  tf.Tensor(0.0052807606, shape=(), dtype=float32)\n",
      "lr:  762.8792359023531\n",
      "dim:  tf.Tensor(-1.8404797e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.01063699, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss (for one batch) at epoch 222: 0.02044202\n",
      "grad:  tf.Tensor(0.004359427, shape=(), dtype=float32)\n",
      "lr:  2052.1512380621443\n",
      "dim:  tf.Tensor(-2.2612512e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.019500159, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss (for one batch) at epoch 224: 0.02043753\n",
      "grad:  tf.Tensor(0.004770263, shape=(), dtype=float32)\n",
      "lr:  2358.7538380894052\n",
      "dim:  tf.Tensor(-2.3692846e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.026837206, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss (for one batch) at epoch 226: 0.02043101\n",
      "grad:  tf.Tensor(0.008072333, shape=(), dtype=float32)\n",
      "lr:  6345.066664966331\n",
      "dim:  tf.Tensor(-4.5485795e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.20673043, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss (for one batch) at epoch 228: 0.02037279\n",
      "grad:  tf.Tensor(0.030061545, shape=(), dtype=float32)\n",
      "lr:  93486.81979220624\n",
      "dim:  tf.Tensor(-5.4521486e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-42.241856, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss (for one batch) at epoch 230: 0.02032784\n",
      "grad:  tf.Tensor(0.0030944762, shape=(), dtype=float32)\n",
      "lr:  1000.418967043936\n",
      "dim:  tf.Tensor(-3.0510128e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.0047898977, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss (for one batch) at epoch 232: 0.02020461\n",
      "grad:  tf.Tensor(0.008784615, shape=(), dtype=float32)\n",
      "lr:  751.6488823127313\n",
      "dim:  tf.Tensor(-5.441904e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.029002171, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss (for one batch) at epoch 234: 0.02018317\n",
      "grad:  tf.Tensor(0.0052758474, shape=(), dtype=float32)\n",
      "lr:  16942.183052108183\n",
      "dim:  tf.Tensor(-1.6804785e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.23578915, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss (for one batch) at epoch 236: 0.02017821\n",
      "grad:  tf.Tensor(0.0047388664, shape=(), dtype=float32)\n",
      "lr:  2324.0305969970073\n",
      "dim:  tf.Tensor(-2.1513551e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.026095208, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss (for one batch) at epoch 238: 0.02017349\n",
      "grad:  tf.Tensor(0.005056856, shape=(), dtype=float32)\n",
      "lr:  4086.5352945024856\n",
      "dim:  tf.Tensor(-2.9299408e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.052250024, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss (for one batch) at epoch 240: 0.01999835\n",
      "grad:  tf.Tensor(0.030214459, shape=(), dtype=float32)\n",
      "lr:  329784.3775002681\n",
      "dim:  tf.Tensor(-0.00017345883, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-150.5323, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss (for one batch) at epoch 242: 0.01993126\n",
      "grad:  tf.Tensor(0.012037841, shape=(), dtype=float32)\n",
      "lr:  2306.8611348216364\n",
      "dim:  tf.Tensor(-2.1537766e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.16714317, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss (for one batch) at epoch 244: 0.01990465\n",
      "grad:  tf.Tensor(0.009827716, shape=(), dtype=float32)\n",
      "lr:  4056.344808517517\n",
      "dim:  tf.Tensor(-1.4746562e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.19588901, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss (for one batch) at epoch 246: 0.01987896\n",
      "grad:  tf.Tensor(0.003372709, shape=(), dtype=float32)\n",
      "lr:  16692.77698978402\n",
      "dim:  tf.Tensor(-1.978688e-05, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.094941564, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss (for one batch) at epoch 248: 0.01987193\n",
      "grad:  tf.Tensor(0.003178275, shape=(), dtype=float32)\n",
      "lr:  1496.7901145262983\n",
      "dim:  tf.Tensor(-2.315268e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.007559862, shape=(), dtype=float32)\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss (for one batch) at epoch 250: 0.01986729\n",
      "grad:  tf.Tensor(0.0028313897, shape=(), dtype=float32)\n",
      "lr:  1124.589450722627\n",
      "dim:  tf.Tensor(-2.0712614e-06, shape=(), dtype=float32)\n",
      "top:  tf.Tensor(-0.004507786, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Qqs paramètres secondaires\n",
    "tirageMin=0; nbTirages=1;\n",
    "\n",
    "# si =1, tous les exemples ont les mêmes poids\n",
    "sample_weight=1\n",
    "\n",
    "# Algorithme adaptatif de la thèse de Bilel Bensaid\n",
    "algo=\"LC_EGD2\"     \n",
    "# Lancement de l'apprentissage\n",
    "studies = tirages.tirages(tirageMin,nbTirages,name_model,nbNeurons,activations,loss,name_init,params_init,metrics,\n",
    "x_train,y_train,algo,eps,max_epochs,lr,seuil,f1,f2,rho,eps_egd,lambd,beta_1,beta_2,epsilon,amsgrad,sample_weight,\n",
    "\"simple\",x_test,y_test)\n",
    "print(studies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafb9a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52ee87d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
